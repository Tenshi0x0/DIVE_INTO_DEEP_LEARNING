{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94fd74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d6bf4",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b50649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24789\\miniconda3\\envs\\pytorch\\lib\\site-packages\\d2l\\torch.py\n",
      "class HyperParameters:\n",
      "    \"\"\"The base class of hyperparameters.\"\"\"\n",
      "    def save_hyperparameters(self, ignore=[]):\n",
      "        \"\"\"Defined in :numref:`sec_oo-design`\"\"\"\n",
      "        raise NotImplemented\n",
      "\n",
      "    def save_hyperparameters(self, ignore=[]):\n",
      "        \"\"\"Save function arguments into class attributes.\n",
      "    \n",
      "        Defined in :numref:`sec_utils`\"\"\"\n",
      "        frame = inspect.currentframe().f_back\n",
      "        _, _, _, local_vars = inspect.getargvalues(frame)\n",
      "        self.hparams = {k:v for k, v in local_vars.items()\n",
      "                        if k not in set(ignore+['self']) and not k.startswith('_')}\n",
      "        for k, v in self.hparams.items():\n",
      "            setattr(self, k, v)\n",
      "\n",
      "class ProgressBoard(d2l.HyperParameters):\n",
      "    \"\"\"The board that plots data points in animation.\n",
      "\n",
      "    Defined in :numref:`sec_oo-design`\"\"\"\n",
      "    def __init__(self, xlabel=None, ylabel=None, xlim=None,\n",
      "                 ylim=None, xscale='linear', yscale='linear',\n",
      "                 ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'],\n",
      "                 fig=None, axes=None, figsize=(3.5, 2.5), display=True):\n",
      "        self.save_hyperparameters()\n",
      "\n",
      "    def draw(self, x, y, label, every_n=1):\n",
      "        raise NotImplemented\n",
      "\n",
      "    def draw(self, x, y, label, every_n=1):\n",
      "        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n",
      "        Point = collections.namedtuple('Point', ['x', 'y'])\n",
      "        if not hasattr(self, 'raw_points'):\n",
      "            self.raw_points = collections.OrderedDict()\n",
      "            self.data = collections.OrderedDict()\n",
      "        if label not in self.raw_points:\n",
      "            self.raw_points[label] = []\n",
      "            self.data[label] = []\n",
      "        points = self.raw_points[label]\n",
      "        line = self.data[label]\n",
      "        points.append(Point(x, y))\n",
      "        if len(points) != every_n:\n",
      "            return\n",
      "        mean = lambda x: sum(x) / len(x)\n",
      "        line.append(Point(mean([p.x for p in points]),\n",
      "                          mean([p.y for p in points])))\n",
      "        points.clear()\n",
      "        if not self.display:\n",
      "            return\n",
      "        d2l.use_svg_display()\n",
      "        if self.fig is None:\n",
      "            self.fig = d2l.plt.figure(figsize=self.figsize)\n",
      "        plt_lines, labels = [], []\n",
      "        for (k, v), ls, color in zip(self.data.items(), self.ls, self.colors):\n",
      "            plt_lines.append(d2l.plt.plot([p.x for p in v], [p.y for p in v],\n",
      "                                          linestyle=ls, color=color)[0])\n",
      "            labels.append(k)\n",
      "        axes = self.axes if self.axes else d2l.plt.gca()\n",
      "        if self.xlim: axes.set_xlim(self.xlim)\n",
      "        if self.ylim: axes.set_ylim(self.ylim)\n",
      "        if not self.xlabel: self.xlabel = self.x\n",
      "        axes.set_xlabel(self.xlabel)\n",
      "        axes.set_ylabel(self.ylabel)\n",
      "        axes.set_xscale(self.xscale)\n",
      "        axes.set_yscale(self.yscale)\n",
      "        axes.legend(plt_lines, labels)\n",
      "        display.display(self.fig)\n",
      "        display.clear_output(wait=True)\n",
      "\n",
      "class Module(d2l.nn_Module, d2l.HyperParameters):\n",
      "    \"\"\"The base class of models.\n",
      "\n",
      "    Defined in :numref:`sec_oo-design`\"\"\"\n",
      "    def __init__(self, plot_train_per_epoch=2, plot_valid_per_epoch=1):\n",
      "        super().__init__()\n",
      "        self.save_hyperparameters()\n",
      "        self.board = ProgressBoard()\n",
      "\n",
      "    def loss(self, y_hat, y):\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def forward(self, X):\n",
      "        assert hasattr(self, 'net'), 'Neural network is defined'\n",
      "        return self.net(X)\n",
      "\n",
      "    def plot(self, key, value, train):\n",
      "        \"\"\"Plot a point in animation.\"\"\"\n",
      "        assert hasattr(self, 'trainer'), 'Trainer is not inited'\n",
      "        self.board.xlabel = 'epoch'\n",
      "        if train:\n",
      "            x = self.trainer.train_batch_idx / \\\n",
      "                self.trainer.num_train_batches\n",
      "            n = self.trainer.num_train_batches / \\\n",
      "                self.plot_train_per_epoch\n",
      "        else:\n",
      "            x = self.trainer.epoch + 1\n",
      "            n = self.trainer.num_val_batches / \\\n",
      "                self.plot_valid_per_epoch\n",
      "        self.board.draw(x, d2l.numpy(d2l.to(value, d2l.cpu())),\n",
      "                        ('train_' if train else 'val_') + key,\n",
      "                        every_n=int(n))\n",
      "\n",
      "    def training_step(self, batch):\n",
      "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
      "        self.plot('loss', l, train=True)\n",
      "        return l\n",
      "\n",
      "    def validation_step(self, batch):\n",
      "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
      "        self.plot('loss', l, train=False)\n",
      "\n",
      "    def configure_optimizers(self):\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def configure_optimizers(self):\n",
      "        \"\"\"Defined in :numref:`sec_classification`\"\"\"\n",
      "        return torch.optim.SGD(self.parameters(), lr=self.lr)\n",
      "\n",
      "    def apply_init(self, inputs, init=None):\n",
      "        \"\"\"Defined in :numref:`sec_lazy_init`\"\"\"\n",
      "        self.forward(*inputs)\n",
      "        if init is not None:\n",
      "            self.net.apply(init)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from d2l import torch as d2l\n",
    "import inspect\n",
    "\n",
    "print(d2l.__file__)\n",
    "print(inspect.getsource(d2l.HyperParameters))\n",
    "print(inspect.getsource(d2l.ProgressBoard))\n",
    "print(inspect.getsource(d2l.Module))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc98784",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636d9f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'B' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.a =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.b =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere is no self.c =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mB\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m, in \u001b[0;36mB.__init__\u001b[1;34m(self, a, b, c)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b, c):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# self.save_hyperparameters(ignore=['c'])\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.a =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.b =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere is no self.c =\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'B' object has no attribute 'a'"
     ]
    }
   ],
   "source": [
    "# Call the fully implemented HyperParameters class saved in d2l\n",
    "class B(d2l.HyperParameters):\n",
    "    def __init__(self, a, b, c):\n",
    "        # self.save_hyperparameters(ignore=['c'])\n",
    "        print('self.a =', self.a, 'self.b =', self.b)\n",
    "        print('There is no self.c =', not hasattr(self, 'c'))\n",
    "\n",
    "b = B(a=1, b=2, c=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
